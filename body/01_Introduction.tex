\section{Introduction}

In recent years, the popularity of platforms for the storage and transmission of video content has enabled a massive volume of video data production and consumption.
%%
As an example, in 2019, more than one billion hours of YouTube videos were watched per day.\footnote{https://kinsta.com/blog/youtube-stats/}
%%
Let us define relevant people present in a video file as \emph{actors}.
%%
Generating metadata with the identity information of the actors present and their localization both in video frames~(spatial) and timeline~(temporal) can facilitate video indexing, retrieval, recommendation and a series of other tasks.
%%
%This dissertation intends to investigate a method for this spatiotemporal localization and a series of applications that such a method enables. 

In our dissertation, we investigate a method for this spatiotemporal localization of actors in video. For doing that, we take advantage of face detection, embeddings and clustering methods. More precisely, we detect and group similar faces~(ideally from the same actors) in different frames with the use of the aforementioned techniques. This process results in the spatiotemporal localization of the actors present in a given video. With this information, we further propose and investigate different applications that this resulting artifact enables. In the following three subsections we motivate and give a brief description of such applications. The last subsection contains the structure of this dissertation proposal.

\subsection{Video Face Recognition}

The face recognition task has been an active research topic for many years~\cite{survey66}.
%%
Many methodologies have been proposed, most commonly relying on comparing selected facial features of a given image with features of faces within a database.
%%
Using only one sample reference image of a person's face for the comparison may result in classification errors due to factors related to variations in lighting, image resolution, angle, etc.~\cite{598229}.
%%
To overcome this problem, some face recognition approaches use multiple face samples for comparison. However, this strategy does not scale well as the complexity is a function of the number of samples.
%%
Other approaches treat the face recognition task as a classification problem~\cite{dadi2016improved, ghosal}, where a classifier model learns rules to assign faces to previously known classes within a dataset, where each class corresponds to one person.
%%
Nonetheless, this kind of approach does not deal well when new classes are incorporated because of the need to retrain the classification models.
%%
Moreover, when dealing with video, these kinds of methods have to be applied to each frame, again increasing the complexity.
%%
In our work, we propose a cluster-matching-based approach for video face recognition where clustering is used to group faces in both the face dataset and in the target video.
%%
Consequently, classes do not have to be previously known, and the effort spent with annotations is significantly reduced --- as it is done over clusters instead of single images.
%%
Face recognition becomes a task of comparing clusters from the dataset with the ones extracted from images or video sources.
%%
Therefore, our approach is easily scalable and can be used to automatically generate video metadata. 


\subsection{Educational Video Recommendation}

The traditional paradigm of classroom courses centered on the physical presence of a teacher has been gradually giving space to online and hybrid courses, which enables the emergence of VTEs (Virtual Teaching Environment) and MOOCs~(\textit{Massive Open Online Courses}).
%%
If, on the one hand, the abundance of educational videos can contribute to and facilitate learning, on the other hand, it also makes it challenging to discover and access the content of interest~\cite{dias2017approach}.
This issue is usually addressed by a proactive user search (using queries, for example), or by automatic recommendations made by specialized systems.
%%
In general, the current video recommendation methods are heavily dependent on textual information from the video, such as labels (\textit{i.e.} keywords)~\cite{mahajan2015optimising,omisore2014personalized}, or automatically generated captions \cite{barrere2020utilizaccao} from the lecturer speech.
These systems face problems such as errors introduced by manually inserted labels and by imprecise speech recognition.
%%
In our work, we aim at recommending educational video content based on actors~(in this specific case, lecturers) presence.
%%
To do that, we take advantage of face detection methods.
More precisely, we detect lecturers in a video taken as a reference and perform a clustering based on the face of these lecturers in different videos.
%%
Given these clusters, we extract their \textit{centroids}, and perform another clustering step for creating a relationship between videos that share the presence of the same lecturers.
%%
Finally, we rank the recommended videos based on the amount of time the referenced lecturers were present.
A particular feature of this approach is that it can be done without supervision, allowing for new videos to be automatically analyzed.

\subsection{Subtitles Positioning in 360-Video}

 The recent popularization of omnidirectional cameras and Head-Mounted-Displays (HMDs) has increased the amount of 360-video content available \cite{mendes2020authoring}. Omnidirectional videos are spherical visual signals that allow the viewer to look around a full 360-degree view of a scene from a specific point.
%%
Several people use subtitles when consuming audiovisual media, and these subtitles are important in contributing to the understanding of the video content \cite{brown_subtitles_2017}. There are also people who choose to consume videos muted \cite{hughes_disruptive_2019}. Additionally, the work of \cite{hayati2011effect}, as referenced in \cite{hughes_disruptive_2019}, shows that consumers are more likely to watch videos entirely if they have subtitles presented with them. In traditional 2D videos, static subtitles are commonly used and they are usually placed at the bottom-center of the screen \cite{rothe_dynamic_2018}.
%%
Different from traditional 2D videos, subtitles positioning in 360-videos is challenging because it involves both temporal and spatial domains \cite{agullo2019making}, and there is no ``center-bottom" of the screen in a 360-video \cite{brown_subtitles_2017}. Most current solutions rely on positioning subtitles either statically to the viewer or at a fixed position in the 360-degree environment %\cite{mendes2020authoring}.
%%
In our work, we adapt our current solution for the spatiotemporal localisation of actors to the 360-video domain. By doing that, we intend to use this localisation for positioning subtitles close to the actors in the 360-video.

\subsection{Structure of this Dissertation Proposal}

The remainder of this dissertation proposal is structured as follows. In Section \ref{sec:related_work}, we discuss some works related to each of our applications.
In Section \ref{sec:video_face_clustering}, we define our approach for spatiotemporal localization of actors.
Section \ref{sec:applications} details our proposed applications. In Section \ref{sec_contritutions}, we highlight the contributions our work have already achieved. Section \ref{sec_expected} points out the overall contributions we expect to achieve by the end of our dissertation. Finally, Section \ref{sec_schedule} shows the schedule we propose for concluding the remaining tasks of our work.

